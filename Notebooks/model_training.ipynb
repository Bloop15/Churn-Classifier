{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09100646",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03cf0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, make_scorer\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d01cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd90bd4",
   "metadata": {},
   "source": [
    "## Load The Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f747978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data loaded successfully!\n",
      "X_train shape: (5625, 46)\n",
      "y_train shape: (5625,)\n",
      "X_test shape: (1407, 46)\n",
      "y_test shape: (1407,)\n"
     ]
    }
   ],
   "source": [
    "# Load the Processed Data\n",
    "X_train= pd.read_csv('../data/X_train_processed.csv')\n",
    "X_test= pd.read_csv('../data/X_test_processed.csv')\n",
    "y_train= pd.read_csv('../data/y_train.csv')\n",
    "y_test= pd.read_csv('../data/y_test.csv')\n",
    "\n",
    "# Convert y_train and y_test from Dataframes to Series\n",
    "y_train= y_train.squeeze()\n",
    "y_test= y_test.squeeze()\n",
    "\n",
    "print(\"Processed data loaded successfully!\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d23667",
   "metadata": {},
   "source": [
    "## Training The Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2db3660",
   "metadata": {},
   "source": [
    "### Baseline Model with DummyClassifier\n",
    "\n",
    "In machine learning, establishing a **baseline** is crucial. A baseline is a simple model that acts as a **reference point**.  \n",
    "If more complex models cannot outperform this baseline, they provide little to no added value.\n",
    "\n",
    "---\n",
    "\n",
    "### Why DummyClassifier?\n",
    "- The dataset is **imbalanced**, with most customers not churning.  \n",
    "- A `DummyClassifier` that always predicts **\"No Churn\"** will still achieve a relatively high **accuracy**.  \n",
    "- This performance represents the **minimum benchmark** our real models must surpass to be considered effective.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea09031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier Performance: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.734186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846721</td>\n",
       "      <td>1033.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>374.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.734186</td>\n",
       "      <td>0.734186</td>\n",
       "      <td>0.734186</td>\n",
       "      <td>0.734186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.367093</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.423361</td>\n",
       "      <td>1407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.539029</td>\n",
       "      <td>0.734186</td>\n",
       "      <td>0.621651</td>\n",
       "      <td>1407.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.734186  1.000000  0.846721  1033.000000\n",
       "1              0.000000  0.000000  0.000000   374.000000\n",
       "accuracy       0.734186  0.734186  0.734186     0.734186\n",
       "macro avg      0.367093  0.500000  0.423361  1407.000000\n",
       "weighted avg   0.539029  0.734186  0.621651  1407.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an instance and train the DummyClassifier model\n",
    "dummy_clf= DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_dummy= dummy_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Dummy Classifier Performance: \")\n",
    "report_dict= classification_report(y_test, y_pred_dummy, output_dict=True)\n",
    "report_df= pd.DataFrame(report_dict).T\n",
    "display(report_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6fa926",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "- The classifier achieves **73.4% accuracy** by predicting only the majority class (No Churn).  \n",
    "- However, it completely **fails to identify churned customers (Class 1)** — precision, recall, and F1-score are **zero** for this class.  \n",
    "- This highlights why **accuracy alone is misleading** on imbalanced datasets, and why we must focus on other metrics (recall, F1-score, precision) for meaningful evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df19ad4",
   "metadata": {},
   "source": [
    "## Train the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7cd45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the models.....\n",
      "-Logistic Regression trained\n",
      "-Decision Tree trained\n",
      "-Random Forest trained\n",
      "-XGBoost trained\n",
      "-SVM trained\n",
      "\n",
      "All the models trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Iniatilize the models with class imbalance handling\n",
    "log_reg_model= LogisticRegression(random_state=42, class_weight='balanced')\n",
    "dt_model= DecisionTreeClassifier(random_state=42)\n",
    "rf_model= RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# scale_pos_weight is the ratio of negative class instances to positive class instances\n",
    "scale_pos_weight_value = (y_train == 0).sum()/(y_train == 1).sum()\n",
    "xgb_model= XGBClassifier(random_state=42, scale_pos_weight=scale_pos_weight_value, eval_metric='logloss', use_label_encoder=False)\n",
    "svm_model= SVC(random_state=42, class_weight='balanced', probability=True) # probability=True is needed for ROC-AUC later\n",
    "\n",
    "# Dictionary of all models to train\n",
    "models_to_train= {\n",
    "    'Logistic Regression': log_reg_model,\n",
    "    'Decision Tree': dt_model,\n",
    "    'Random Forest': rf_model,\n",
    "    'XGBoost': xgb_model,\n",
    "    'SVM': svm_model\n",
    "}\n",
    "\n",
    "# Dictionary to store models\n",
    "models= {}\n",
    "\n",
    "print(\"Training the models.....\")\n",
    "\n",
    "for name, model in models_to_train.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    models[name]= model\n",
    "    print(f\"-{name} trained\")\n",
    " \n",
    "print(\"\\nAll the models trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ac41e",
   "metadata": {},
   "source": [
    "## Evaluate the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fdb62e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models using StratifiedKFold CV.....\n",
      "-Logistic Regression evaluated on CV\n",
      "-Decision Tree evaluated on CV\n",
      "-Random Forest evaluated on CV\n",
      "-XGBoost evaluated on CV\n",
      "-SVM evaluated on CV\n",
      "\n",
      "Cross-validated Performance on Training Data: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (Overall)</th>\n",
       "      <th>Recall (Overall)</th>\n",
       "      <th>F1-Score (Overall)</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Precision (Churn)</th>\n",
       "      <th>Recall (Churn)</th>\n",
       "      <th>F1-Score (Churn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.751822</td>\n",
       "      <td>0.521531</td>\n",
       "      <td>0.802007</td>\n",
       "      <td>0.632051</td>\n",
       "      <td>0.845603</td>\n",
       "      <td>0.521531</td>\n",
       "      <td>0.802007</td>\n",
       "      <td>0.632051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.750400</td>\n",
       "      <td>0.520106</td>\n",
       "      <td>0.787291</td>\n",
       "      <td>0.626397</td>\n",
       "      <td>0.826055</td>\n",
       "      <td>0.520106</td>\n",
       "      <td>0.787291</td>\n",
       "      <td>0.626397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.772622</td>\n",
       "      <td>0.562284</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.603902</td>\n",
       "      <td>0.827030</td>\n",
       "      <td>0.562284</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.603902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.788622</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.481605</td>\n",
       "      <td>0.547737</td>\n",
       "      <td>0.822896</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.481605</td>\n",
       "      <td>0.547737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.727111</td>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.494983</td>\n",
       "      <td>0.490879</td>\n",
       "      <td>0.652752</td>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.494983</td>\n",
       "      <td>0.490879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Precision (Overall)  Recall (Overall)  \\\n",
       "Logistic Regression  0.751822             0.521531          0.802007   \n",
       "SVM                  0.750400             0.520106          0.787291   \n",
       "XGBoost              0.772622             0.562284          0.652174   \n",
       "Random Forest        0.788622             0.634921          0.481605   \n",
       "Decision Tree        0.727111             0.486842          0.494983   \n",
       "\n",
       "                     F1-Score (Overall)   ROC-AUC  Precision (Churn)  \\\n",
       "Logistic Regression            0.632051  0.845603           0.521531   \n",
       "SVM                            0.626397  0.826055           0.520106   \n",
       "XGBoost                        0.603902  0.827030           0.562284   \n",
       "Random Forest                  0.547737  0.822896           0.634921   \n",
       "Decision Tree                  0.490879  0.652752           0.486842   \n",
       "\n",
       "                     Recall (Churn)  F1-Score (Churn)  \n",
       "Logistic Regression        0.802007          0.632051  \n",
       "SVM                        0.787291          0.626397  \n",
       "XGBoost                    0.652174          0.603902  \n",
       "Random Forest              0.481605          0.547737  \n",
       "Decision Tree              0.494983          0.490879  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Dictionary to store results\n",
    "cv_results= {}\n",
    "detailed_cv_reports= {}\n",
    "\n",
    "print(\"Evaluating models using StratifiedKFold CV.....\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred_cv= cross_val_predict(model, X_train, y_train, cv=cv, method='predict')\n",
    "    y_proba_cv= cross_val_predict(model, X_train, y_train, cv=cv, method='predict_proba')[:, 1] \\\n",
    "                if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Overall Metrics\n",
    "    accuracy= accuracy_score(y_train, y_pred_cv)\n",
    "    precision= precision_score(y_train, y_pred_cv, zero_division=0)\n",
    "    recall= recall_score(y_train, y_pred_cv, zero_division=0)\n",
    "    f1= f1_score(y_train, y_pred_cv, zero_division=0)\n",
    "    roc_auc= roc_auc_score(y_train, y_proba_cv) if y_proba_cv is not None else 'NA'\n",
    "\n",
    "    # Churn Class Metrics\n",
    "    report= classification_report(y_train, y_pred_cv, output_dict=True, zero_division=0)\n",
    "    churn_precision= report['1']['precision']\n",
    "    churn_recall= report['1']['recall']\n",
    "    churn_f1= report['1']['f1-score']\n",
    "\n",
    "    # Store the results\n",
    "    cv_results[name]= {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision (Overall)': precision,\n",
    "        'Recall (Overall)': recall,\n",
    "        'F1-Score (Overall)': f1,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'Precision (Churn)': churn_precision,\n",
    "        'Recall (Churn)': churn_recall,\n",
    "        'F1-Score (Churn)': churn_f1\n",
    "\n",
    "    }\n",
    "\n",
    "    # Store the detailed Per-Class Report\n",
    "    detailed_cv_reports[name]= pd.DataFrame(report).T\n",
    "\n",
    "    print(f\"-{name} evaluated on CV\")\n",
    "\n",
    "# Summary DataFrame\n",
    "cv_results_df= pd.DataFrame(cv_results).T\n",
    "print(\"\\nCross-validated Performance on Training Data: \")\n",
    "display(cv_results_df.sort_values(by='F1-Score (Churn)', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9435dda",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Observations\n",
    "\n",
    "- **DummyClassifier (Baseline)** achieved ~73.4% accuracy by always predicting “No Churn”.  \n",
    "- **Logistic Regression** achieved the **highest recall (0.802)** for churn customers, making it strong at identifying churners, though at the cost of lower precision.  \n",
    "- **SVM** performed similarly to Logistic Regression, with balanced precision and recall but slightly lower overall metrics.  \n",
    "- **XGBoost** provided a better balance between precision and recall compared to Logistic Regression but did not outperform it in F1-score for churn.  \n",
    "- **Random Forest** achieved the **highest accuracy (0.789)** and precision but suffered from **low recall (0.482)**, meaning it misses many churners.  \n",
    "- **Decision Tree** had the weakest overall performance, with low F1-scores and ROC-AUC.  \n",
    "\n",
    "---\n",
    "\n",
    "### Best-Performing Models\n",
    "\n",
    "- **Logistic Regression** – Best for **identifying churners** (high recall and F1 for churn, ROC-AUC = 0.846).  \n",
    "- **Random Forest** – Best for **overall accuracy and precision**, but weaker at capturing churners.  \n",
    "- **XGBoost** – Offers a **middle ground**, with balanced performance across metrics and competitive ROC-AUC.  \n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaways:**  \n",
    "- **Logistic Regression** excels at **detecting churners**, which is often more important than overall accuracy in churn prediction.  \n",
    "- **Random Forest** is best if the goal is **high overall accuracy**.  \n",
    "- **XGBoost** gives a **balanced approach**, making it a strong candidate for further hyperparameter tuning.  \n",
    "- The **DummyClassifier** highlights that naive accuracy can be misleading when the dataset is imbalanced.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ee231",
   "metadata": {},
   "source": [
    "## Broad HyperParameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff1af938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing broad search for Logistic Regression.....\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best params: {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 1000, 'C': np.float64(0.46415888336127775)}\n",
      "Best CV F1-Score (Churn): 0.6329\n",
      "Best CV ROC-AUC: 0.8457\n",
      "--------------------------------------------------\n",
      "\n",
      "Performing broad search for Random Forest.....\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best params: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n",
      "Best CV F1-Score (Churn): 0.6406\n",
      "Best CV ROC-AUC: 0.8488\n",
      "--------------------------------------------------\n",
      "\n",
      "Performing broad search for XGBoost.....\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best params: {'subsample': 0.5, 'reg_lambda': 1, 'reg_alpha': 0.01, 'n_estimators': 1000, 'min_child_weight': 3, 'max_depth': 7, 'learning_rate': 0.001, 'gamma': 1, 'colsample_bytree': 0.5}\n",
      "Best CV F1-Score (Churn): 0.6398\n",
      "Best CV ROC-AUC: 0.8495\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Parameter Grids\n",
    "param_dist_lr= {\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"C\": np.logspace(-3, 3, 10),\n",
    "    \"solver\": [\"liblinear\", \"saga\"],\n",
    "    \"max_iter\": [100, 500, 1000],\n",
    "\n",
    "}\n",
    "\n",
    "param_dist_rf= {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 5, 10, 20 ,50],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 10],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"bootstrap\": [True, False] \n",
    "\n",
    "}\n",
    "\n",
    "param_dist_xgb= {\n",
    "    \"n_estimators\": [100, 300, 500, 1000],\n",
    "    \"learning_rate\": [0.001, 0.01, 0.05, 0.1, 0.2],\n",
    "    \"max_depth\": [3, 5, 7, 10],\n",
    "    \"min_child_weight\": [1, 3, 5, 10],\n",
    "    \"subsample\": [0.5, 0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.5, 0.7, 0.8, 1.0],\n",
    "    \"gamma\": [0, 0.1, 0.3, 0.5, 1],\n",
    "    \"reg_alpha\": [0, 0.01, 0.1, 1, 10],\n",
    "    \"reg_lambda\": [0, 0.01, 0.1, 1, 10]\n",
    "\n",
    "}\n",
    "\n",
    "#Models\n",
    "models_to_tune= {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric= 'logloss', use_label_encoder=False, verbosity=0)\n",
    "\n",
    "}\n",
    "\n",
    "param_dists= {\n",
    "    'Logistic Regression': param_dist_lr,\n",
    "    'Random Forest': param_dist_rf,\n",
    "    'XGBoost': param_dist_xgb\n",
    "\n",
    "}\n",
    "\n",
    "# Scores\n",
    "scorers= {\n",
    "    \"f1_churn\": make_scorer(f1_score, pos_label=1),\n",
    "    \"roc_auc\": \"roc_auc\"\n",
    "}\n",
    "\n",
    "# Result containers\n",
    "best_models, best_scorers, best_params= {}, {}, {}\n",
    "all_results= {}\n",
    "\n",
    "cv_folds= StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models_to_tune.items():\n",
    "    print(f\"\\nPerforming broad search for {name}.....\")\n",
    "\n",
    "    if name=='XGBoost':\n",
    "        scale_pos_weight_value= (y_train==0).sum()/(y_train==1).sum()\n",
    "        model.set_params(scale_pos_weight= scale_pos_weight_value)\n",
    "\n",
    "    random_search= RandomizedSearchCV(\n",
    "        estimator= model,\n",
    "        param_distributions= param_dists[name],\n",
    "        n_iter= 50,\n",
    "        cv= cv_folds,\n",
    "        scoring= scorers,\n",
    "        refit= \"f1_churn\",\n",
    "        n_jobs= -1,\n",
    "        verbose= 1,\n",
    "        random_state=42, \n",
    "        return_train_score= True\n",
    "\n",
    "    )\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Store Best\n",
    "    best_models[name]= random_search.best_estimator_\n",
    "    best_scorers[name]= {\n",
    "        \"Best F1 (Churn)\": random_search.cv_results_[\"mean_test_f1_churn\"][random_search.best_index_],\n",
    "        \"Best ROC_AUC\": random_search.cv_results_[\"mean_test_roc_auc\"][random_search.best_index_]\n",
    "\n",
    "    }\n",
    "    best_params[name]= random_search.best_params_\n",
    "    all_results[name]= pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "    print(f\"Best params: {random_search.best_params_}\")\n",
    "    print(f\"Best CV F1-Score (Churn): {best_scorers[name]['Best F1 (Churn)']:.4f}\")\n",
    "    print(f\"Best CV ROC-AUC: {best_scorers[name]['Best ROC_AUC']:.4f}\")\n",
    "    print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7021f2",
   "metadata": {},
   "source": [
    "## Fine_Tuning HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59ceb53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing fine-tuning for Logistic Regression.....\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "\n",
      "Best parameters for Tuned Logistic Regression: {'C': np.float64(0.8), 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best CV F1-Score (Churn): 0.6333\n",
      "Best CV ROC-AUC: 0.8458\n"
     ]
    }
   ],
   "source": [
    "# Fine tuning Logistic Regression\n",
    "param_grid_lr_fine= {\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"C\": np.linspace(0.1, 1, 10),\n",
    "    \"solver\": [\"liblinear\", \"saga\"],\n",
    "    \"max_iter\": [500, 1000, 1500]\n",
    "\n",
    "}\n",
    "\n",
    "grid_search_lr= GridSearchCV(\n",
    "    estimator= LogisticRegression(random_state=42, class_weight='balanced'),\n",
    "    param_grid=param_grid_lr_fine,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=scorers,\n",
    "    refit='f1_churn',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    "\n",
    ")\n",
    "\n",
    "# Result containers\n",
    "best_models_tuned, best_scorers_tuned, best_params_tuned= {}, {}, {}\n",
    "all_results_tuned= {}\n",
    "\n",
    "print(\"Performing fine-tuning for Logistic Regression.....\")\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Store best results\n",
    "best_models_tuned['Logistic Regression (Tuned)']= grid_search_lr.best_estimator_\n",
    "best_scorers_tuned['Logistic Regression (Tuned)']= {\n",
    "    \"Best F1 (Churn)\": grid_search_lr.cv_results_[\"mean_test_f1_churn\"][grid_search_lr.best_index_],\n",
    "    \"Best ROC_AUC\": grid_search_lr.cv_results_[\"mean_test_roc_auc\"][grid_search_lr.best_index_]\n",
    "}\n",
    "best_params_tuned['Logistic Regression (Tuned)']= grid_search_lr.best_params_\n",
    "\n",
    "print(f\"\\nBest parameters for Tuned Logistic Regression: {grid_search_lr.best_params_}\")\n",
    "print(f\"Best CV F1-Score (Churn): {best_scorers_tuned['Logistic Regression (Tuned)'][\"Best F1 (Churn)\"]:.4f}\" )\n",
    "print(f\"Best CV ROC-AUC: {best_scorers_tuned['Logistic Regression (Tuned)'][\"Best ROC_AUC\"]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d2c334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing fine-tuning for Random Forest.....\n",
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
      "\n",
      "Best parameters for Tuned Random Forest: {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best CV F1-Score (Churn): 0.6406\n",
      "Best CV ROC-AUC: 0.8488\n"
     ]
    }
   ],
   "source": [
    "# Fine Tuning Random Forest\n",
    "param_grid_rf_fine= {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [8, 9, 10, 11, 12, 15],\n",
    "    \"min_samples_split\": [2, 3, 5],\n",
    "    \"min_samples_leaf\": [8, 9, 10, 11, 12],\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "grid_search_rf= GridSearchCV(\n",
    "    estimator= RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    param_grid= param_grid_rf_fine,\n",
    "    cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring= scorers,\n",
    "    refit= \"f1_churn\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"Performing fine-tuning for Random Forest.....\")\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Store best results\n",
    "best_models_tuned['Random Forest (Tuned)']= grid_search_rf.best_estimator_\n",
    "best_scorers_tuned['Random Forest (Tuned)']= {\n",
    "    \"Best F1 (Churn)\": grid_search_rf.cv_results_[\"mean_test_f1_churn\"][grid_search_rf.best_index_],\n",
    "    \"Best ROC_AUC\": grid_search_rf.cv_results_[\"mean_test_roc_auc\"][grid_search_rf.best_index_]\n",
    "}\n",
    "best_params_tuned['Random Forest (Tuned)']= grid_search_rf.best_params_\n",
    "\n",
    "print(f\"\\nBest parameters for Tuned Random Forest: {grid_search_rf.best_params_}\")\n",
    "print(f\"Best CV F1-Score (Churn): {best_scorers_tuned['Random Forest (Tuned)'][\"Best F1 (Churn)\"]:.4f}\")\n",
    "print(f\"Best CV ROC-AUC: {best_scorers_tuned['Random Forest (Tuned)'][\"Best ROC_AUC\"]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f66ab9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing fine-tuining for XGBoost.....\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "\n",
      "Best parameters for Tuned XGBoost: {'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 0.005, 'n_estimators': 800, 'min_child_weight': 3, 'max_depth': 7, 'learning_rate': 0.005, 'gamma': 1, 'colsample_bytree': 0.4}\n",
      "Best CV F1-Score (Churn): 0.6418\n",
      "Best CV ROC-AUC: 0.8481\n"
     ]
    }
   ],
   "source": [
    "# Fine Tuning XGBoost\n",
    "param_dist_xgb_fine= {\n",
    "    \"n_estimators\": [800, 1000, 1200],\n",
    "    \"learning_rate\": [0.001, 0.005, 0.01],\n",
    "    \"max_depth\": [6, 7, 8],\n",
    "    \"min_child_weight\": [2, 3, 4],\n",
    "    \"subsample\": [0.4, 0.5, 0.6],\n",
    "    \"colsample_bytree\": [0.4, 0.5, 0.6],\n",
    "    \"gamma\": [0.5, 1, 1.5],\n",
    "    \"reg_alpha\": [0.005, 0.01, 0.05],\n",
    "    \"reg_lambda\": [0.5, 1, 2]\n",
    "\n",
    "}\n",
    "\n",
    "scale_pos_weight_value= (y_train==0).sum()/(y_train==1).sum()\n",
    "\n",
    "random_search_xgb= RandomizedSearchCV(\n",
    "    estimator=XGBClassifier(random_state=42,scale_pos_weight= scale_pos_weight_value, eval_metric='logloss', use_label_encoder=False),\n",
    "    param_distributions=param_dist_xgb_fine,\n",
    "    n_iter=200,\n",
    "    cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=scorers,\n",
    "    refit=\"f1_churn\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Performing fine-tuining for XGBoost.....\")\n",
    "random_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Store best results\n",
    "best_models_tuned['XGBoost (Tuned)']= random_search_xgb.best_estimator_\n",
    "best_scorers_tuned['XGBoost (Tuned)']= {\n",
    "    \"Best F1 (Churn)\": random_search_xgb.cv_results_[\"mean_test_f1_churn\"][random_search_xgb.best_index_],\n",
    "    \"Best ROC_AUC\": random_search_xgb.cv_results_[\"mean_test_roc_auc\"][random_search_xgb.best_index_]\n",
    "}\n",
    "best_params_tuned['XGBoost (Tuned)']= random_search_xgb.best_params_\n",
    "\n",
    "print(f\"\\nBest parameters for Tuned XGBoost: {random_search_xgb.best_params_}\")\n",
    "print(f\"Best CV F1-Score (Churn): {best_scorers_tuned['XGBoost (Tuned)'][\"Best F1 (Churn)\"]:.4f}\")\n",
    "print(f\"Best CV ROC-AUC: {best_scorers_tuned['XGBoost (Tuned)'][\"Best ROC_AUC\"]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9087206f",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **Logistic Regression**: Performs decently with strong ROC-AUC but lags behind tree-based models in F1, making it more suitable as a baseline or for interpretability.\n",
    "\n",
    "- **Random Forest**: Offers balanced performance with good F1 and ROC-AUC, showing that controlled tree depth and regularization prevent overfitting.\n",
    "\n",
    "- **XGBoost**: Achieves the best overall performance, slightly outperforming Random Forest in F1 while maintaining high ROC-AUC, making it the most effective model for churn prediction.\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Evolution\n",
    "**Logistic Regression**\n",
    "\n",
    "- Initial Training: Strong ROC-AUC (0.8456) and decent F1 (0.6321), indicating it’s a reliable baseline.\n",
    "\n",
    "- Broad Search: Achieved small improvements in F1 (0.6329) and ROC-AUC (0.8457), showing robustness but limited capacity to capture complex churn patterns.\n",
    "\n",
    "- Fine-Tuning: Results stayed consistent (F1= 0.6333, ROC-AUC= 0.8458), suggesting diminishing returns from additional tuning.\n",
    "\n",
    "**Random Forest**\n",
    "\n",
    "- Initial Training: Produced balanced results (F1= 0.5477, ROC-AUC= 0.8229), but recall on churn cases was weaker.\n",
    "\n",
    "- Broad Search: Significant boost in F1 (0.6406) and ROC-AUC (0.8488), showing that hyperparameter control improves generalization.\n",
    "\n",
    "- Fine-Tuning: Performance plateaued (same F1= 0.6406, ROC-AUC= 0.8488), indicating the model already reached an optimal region.\n",
    "\n",
    "**XGBoost**\n",
    "\n",
    "- Initial Training: Started lower than Random Forest in F1 (0.6039) but with decent ROC-AUC (0.8270).\n",
    "\n",
    "- Broad Search: Clear gains (F1= 0.6398, ROC-AUC= 0.8495), proving tuning has strong impact on boosting methods.\n",
    "\n",
    "- Fine-Tuning: Marginal improvements in F1 (0.6418 vs. 0.6398) but slight dip in ROC-AUC (0.8481 vs. 0.8495), suggesting the model is near its performance ceiling.\n",
    "\n",
    "---\n",
    "\n",
    "### Overall Insight\n",
    "Logistic Regression started as the strongest baseline with high recall and competitive ROC-AUC, making it effective for identifying churners. Random Forest showed clear gains from hyperparameter tuning. After fine-tuning, however, XGBoost slightly outperformed the others, offering the best balance of F1 and ROC-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873de09f",
   "metadata": {},
   "source": [
    "## Retrain Final Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07cb64f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining final models on the complete training dataset with best parameters....\n",
      "-Logistic Regression (Tuned) retrained with best parameters\n",
      "-Random Forest (Tuned) retrained with best parameters\n",
      "-XGBoost (Tuned) retrained with best parameters\n"
     ]
    }
   ],
   "source": [
    "# Refit the best models of all the fine-tuned models on complete training dataset\n",
    "print(\"Retraining final models on the complete training dataset with best parameters....\")\n",
    "for name, model in best_models_tuned.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"-{name} retrained with best parameters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd404e3",
   "metadata": {},
   "source": [
    "## Final Model Evaluation on Hold-Out Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53841fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating final models on the hold-out test set.....\n",
      "--------------------------------------------------\n",
      "Logistic Regression (Tuned) Final Evaluation: \n",
      "    Accuracy: 0.7271\n",
      "    F1-Score (Churn): 0.6082\n",
      "    ROC-AUC: 0.8357193885210513\n",
      "--------------------------------------------------\n",
      "Random Forest (Tuned) Final Evaluation: \n",
      "    Accuracy: 0.7527\n",
      "    F1-Score (Churn): 0.6266\n",
      "    ROC-AUC: 0.8351991240921256\n",
      "--------------------------------------------------\n",
      "XGBoost (Tuned) Final Evaluation: \n",
      "    Accuracy: 0.7392\n",
      "    F1-Score (Churn): 0.6092\n",
      "    ROC-AUC: 0.8346710945224698\n",
      "--------------------------------------------------\n",
      "Summary of Final Test Set Results: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score (Churn)</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest (Tuned)</th>\n",
       "      <td>0.7527</td>\n",
       "      <td>0.6266</td>\n",
       "      <td>0.8352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost (Tuned)</th>\n",
       "      <td>0.7392</td>\n",
       "      <td>0.6092</td>\n",
       "      <td>0.8347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (Tuned)</th>\n",
       "      <td>0.7271</td>\n",
       "      <td>0.6082</td>\n",
       "      <td>0.8357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Accuracy  F1-Score (Churn)  ROC-AUC\n",
       "Random Forest (Tuned)          0.7527            0.6266   0.8352\n",
       "XGBoost (Tuned)                0.7392            0.6092   0.8347\n",
       "Logistic Regression (Tuned)    0.7271            0.6082   0.8357"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fine_tuned_results= {}\n",
    "\n",
    "print(\"Evaluating final models on the hold-out test set.....\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for name, model in best_models_tuned.items():\n",
    "    y_pred= model.predict(X_test)\n",
    "    y_proba= model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    accuracy= accuracy_score(y_test, y_pred)\n",
    "    f1= f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "    roc_auc= roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    fine_tuned_results[name]= {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1-Score (Churn)\": f1,\n",
    "        \"ROC-AUC\": roc_auc\n",
    "    }\n",
    "\n",
    "    print(f\"{name} Final Evaluation: \")\n",
    "    print(f\"    Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"    F1-Score (Churn): {f1:.4f}\")\n",
    "    print(f\"    ROC-AUC: {roc_auc}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "\n",
    "fine_tuned_df= pd.DataFrame(fine_tuned_results).T\n",
    "print(\"Summary of Final Test Set Results: \")\n",
    "display(fine_tuned_df.sort_values(by=\"F1-Score (Churn)\", ascending=False).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828556ff",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Key Observations\n",
    "**Logistic Regression**\n",
    "- Lowest accuracy among the three (0.7271).\n",
    "- F1-Score for churners (0.6082) is close to **XGBoost** but below **Random Forest**.\n",
    "- Achieved the highest ROC-AUC (0.8357) showing strong ranking ability despite lowest accuracy.\n",
    "\n",
    "**Random Forest**\n",
    "- Best overall performer with highest accuracy (0.7527) and F1-Score for churn (0.6266).\n",
    "- ROC-AUC (0.8352) is compitetive and only slightly lower than **Logistic Regression**.\n",
    "- Demostrates a good balance of precision and recall on the hold-out test set.\n",
    "\n",
    "**XGBoost**\n",
    "- Middle ground with accuracy (0.7392) higher than **Logistic Regression** but lowen than **Random Forest**.\n",
    "- F1-Score (0.6092) nearly matches **Logistic Regression**, but below **Random Forest**.\n",
    "- ROC-AUC (0.8347) is the lowest of the three but still very strong.\n",
    "\n",
    "\n",
    "**Conclusion:** *Random Forest* is the top-performing model on the hold-out test set, achieving the best accuracy and F1-Score, with strong ROC-AUC. *XGBoost* is a close competitor, while *Logistic Regression*, though slightly better in ROC-AUC, lags behind in accuracy and F1-Score. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bd5079",
   "metadata": {},
   "source": [
    "## Save The Required Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d35d38d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (Tuned) model saved to '../models/Logistic Regression (Tuned)_model.pkl'\n",
      "Random Forest (Tuned) model saved to '../models/Random Forest (Tuned)_model.pkl'\n",
      "XGBoost (Tuned) model saved to '../models/XGBoost (Tuned)_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Save the three final trained models\n",
    "for name, model in best_models_tuned.items():\n",
    "    joblib.dump(model, f'../models/{name}_model.pkl')\n",
    "    print(f\"{name} model saved to '../models/{name}_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49a2d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the test results\n",
    "fine_tuned_df.to_csv('../results/test_results.csv', index= True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
